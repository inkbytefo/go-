package parser

import (
	"goplus/internal/ast"
	"goplus/internal/lexer"
	"goplus/internal/token"
)

// Parser, token dizisini Soyut Sözdizimi Ağacı'na (AST) dönüştürür.
// TODO: Parser struct'ını ve AST oluşturma metotlarını implemente et.
type Parser struct {
	l      *lexer.Lexer
	errors []string

	curToken  lexer.Token
	peekToken lexer.Token

	// TODO: AST düğümlerini (nodes) ve ifadelerini (expressions) ayrıştırmak için
	// prefix ve infix ayrıştırma fonksiyonları için haritalar eklenecek.
	// prefixParseFns map[token.TokenType]prefixParseFn
	// infixParseFns  map[token.TokenType]infixParseFn
}

// New, yeni bir Parser oluşturur.
func New(l *lexer.Lexer) *Parser {
	p := &Parser{
		l:      l,
		errors: []string{},
	}

	// İki token oku, böylece curToken ve peekToken ayarlanır.
	p.nextToken()
	p.nextToken()

	return p
}

// nextToken bir sonraki token'ı alır.
func (p *Parser) nextToken() {
	p.curToken = p.peekToken
	p.peekToken = p.l.NextToken()
}

// Errors, ayrıştırma sırasında karşılaşılan hataları döndürür.
func (p *Parser) Errors() []string {
	return p.errors
}

// ParseProgram, GO+ programının tamamını ayrıştırır ve bir AST kök düğümü döndürür.
// TODO: Bu ana ayrıştırma fonksiyonudur ve tüm ifadeleri (statements) ayrıştırmalıdır.
func (p *Parser) ParseProgram() *ast.Program {
	program := &ast.Program{}
	program.Statements = []ast.Statement{}

	for p.curToken.Type != string(token.EOF) { // lexer.Token.Type string olduğu için token.EOF'u string'e çeviriyoruz
		// stmt := p.parseStatement() // parseStatement henüz tanımlanmadı
		// if stmt != nil {
		// 	program.Statements = append(program.Statements, stmt)
		// }
		p.nextToken() // Şimdilik sadece tokenları tüketiyoruz
	}
	return program
}

// TODO: parseStatement, parseLetStatement, parseReturnStatement, parseExpressionStatement vb.
// gibi yardımcı ayrıştırma fonksiyonları eklenecek.
// type prefixParseFn func() ast.Expression
// type infixParseFn func(ast.Expression) ast.Expression